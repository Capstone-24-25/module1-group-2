---
title: "Biomarkers of ASD"
author: "Luke Dillon, Johnson Leung, Navin Lo, Edwin Yang"
date: last-modified
published-title: "Updated"
editor: visual
format: html
code-copy: true
execute:
  message: false
  warning: false
  echo: false
  cache: true
---

```{r, echo = F, results = 'hide'}
# load any other packages and read data here
library(tidyverse)
library(dplyr)
library(ggplot2)
library(gridExtra)
```

## Abstract

Write a brief one-paragraph abstract that describes the contents of your write-up.

## Dataset

### The Data

This data for this project came from [Hewiston et al, 2021](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0246581), a study where the researchers were looking to predict ASD (autism spectrum disorder) from a total of 1,125 proteins found in serum samples, and find which of those proteins had the greatest effect on autism in 154 children, specifically boys between the ages of 18 months and 8 years. The average age of child was around 5 and a half years old, and from a relatively wide range of ethnicity, though the distribution varied between the two groups (typical development and ASD). The researchers also took into account what other medical conditions the children had, as well as what medications they were taking at the time of sampling.

The key variables in this study were the levels of each of these 1,125 proteins, as well as ASD severity, which was measured by ADOS (Autism Diagnostic Observation Schedule) scores. Through the use of three methods (random forest, t-tests and correlation analyses), a panel of nine proteins was found to have the highest predictive power for ASD in children. Data preprocessing steps included log transformations, normalization methods, and outlier trimming, before fitting machine learning models to be able to predict ASD based on this panel of proteins.

## Summary of published analysis

Summarize the methodology of the paper in 1-3 paragraphs. You need not explain the methods in depth as we did in class; just indicate what methods were used and how they were combined. If possible, include a diagram that depicts the methodological design. (Quarto has support for [GraphViz and Mermaid flowcharts](https://quarto.org/docs/authoring/diagrams.html).) Provide key results: the proteins selected for the classifier and the estimated accuracy.

## Findings

### Impact of preprocessing and outliers

Looking into why the researchers utilized log-trasnforms.

```{r, echo = F}
var_names <- read_csv('../data/biomarker-raw.csv', 
                     col_names = F, 
                     n_max = 2, 
                     col_select = -(1:2)) %>%
  t() %>%
  as_tibble() %>%
  rename(name = V1, 
         abbreviation = V2) %>%
  na.omit()

biomarker_clean <- read_csv('../data/biomarker-raw.csv', 
         skip = 2,
         col_select = -2L,
         col_names = c('group', 
                       'empty',
                       pull(var_names, abbreviation),
                       'ados'),
         na = c('-', ''),
         show_col_types = FALSE) %>%
  filter(!is.na(group))

# plot individual proteins
p1 <- ggplot(biomarker_clean, aes(x = CHIP)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "CHIP") +
  theme_minimal()

p2 <- ggplot(biomarker_clean, aes(x = CEBPB)) +
  geom_histogram(bins = 30, fill = "orange", color = "black", alpha = 0.7) +
  labs(title = "CEBPB") +
  theme_minimal()

p3 <- ggplot(biomarker_clean, aes(x = PIAS4)) +
  geom_histogram(bins = 30, fill = "green", color = "black", alpha = 0.7) +
  labs(title = "PIAS4") +
  theme_minimal()

# make it a grid
grid.arrange(p1, p2, p3, ncol = 3)
```

After investigating some of the protein levels in `biomarker-raw.csv`, the reason for log-transforming the data is to reduce the significant skew that each of these proteins comes with. As a result, it would be very difficult to perform any analysis on data this skewed.

```{r, echo = F}
# take the log, then look at the same proteins
log_biomarker_clean = biomarker_clean %>%
  mutate(across(.cols=-c(group, ados), ~ log10(.x)))

# plot individual proteins
p1 <- ggplot(log_biomarker_clean, aes(x = CHIP)) +
  geom_histogram(bins = 30, fill = "skyblue", color = "black", alpha = 0.7) +
  labs(title = "CHIP") +
  theme_minimal()

p2 <- ggplot(log_biomarker_clean, aes(x = CEBPB)) +
  geom_histogram(bins = 30, fill = "orange", color = "black", alpha = 0.7) +
  labs(title = "CEBPB") +
  theme_minimal()

p3 <- ggplot(log_biomarker_clean, aes(x = PIAS4)) +
  geom_histogram(bins = 30, fill = "green", color = "black", alpha = 0.7) +
  labs(title = "PIAS4") +
  theme_minimal()

# make it a grid
grid.arrange(p1, p2, p3, ncol = 3)
```

After log transforming the data, it becomes much less skewed, which helps stabilize variance data and makes extreme values less influential. This transformation often "normalizes" the data, allowing for better model accuracy and interpretability.

#### Outlier Analysis

```{r, echo = F}
# reload the data, but do not trim outliers
clean_data_with_outliers <- read_csv('../data/biomarker-raw.csv', 
         skip = 2,
         col_select = -2L,
         col_names = c('group', 
                       'empty',
                       pull(var_names, abbreviation),
                       'ados'),
         na = c('-', ''),
         show_col_types=FALSE) %>%
  filter(!is.na(group)) %>%
  # log transform, center, and scale without trimming
  mutate(across(.cols = -c(group, ados), 
                ~ scale(log10(.x))[, 1])) %>%
  # reorder columns
  select(group, ados, everything())
```

Let's define an outlier as being outside of 3 standard deviations from the mean of a given protein. Take the sum of each protein for a given subject. An "outlier subject" would then be considered someone who is in the 75th percentile or higher in terms of number of outlying proteins in their panel.

```{r, echo = F}
is_outlier <- function(x) {
  abs(scale(x)) > 3 
}

# Apply the outlier detection process and count outliers for each subject
outlier_counts <- clean_data_with_outliers %>%
  # Flag outliers across all protein columns, excluding 'group' and 'ados'
  mutate(across(.cols = -c(group, ados), ~ is_outlier(.x))) %>%
  # Count the number of outliers per subject
  rowwise() %>%
  mutate(outlier_count = sum(c_across(-c(group, ados)))) %>%
  ungroup() %>%
  # Select relevant columns for viewing
  select(group, outlier_count, ados)

percentile_75 = quantile(outlier_counts$outlier_count, 0.75)
percentile_90 = quantile(outlier_counts$outlier_count, 0.9)
percentile_95 = quantile(outlier_counts$outlier_count, 0.95)

outlying_subjects_75 = outlier_counts %>%
  filter(outlier_count > percentile_75)

outlying_subjects_90 = outlier_counts %>%
  filter(outlier_count > percentile_90)

outlying_subjects_95 = outlier_counts %>%
  filter(outlier_count > percentile_95)
```

Let's take a look at how outlying subjects are distributed across the two groups at the 75th, 90th and 90th percentile of outliying proteins.

```{r, echo = F}
outlying_subjects_75 %>%
  group_by(group) %>%
  summarize(count=n())
```

```{r}
outlying_subjects_90 %>%
  group_by(group) %>%
  summarize(count=n())
```

```{r, echo = F}
outlying_subjects_95 %>%
  group_by(group) %>%
  summarize(count=n())
```

By analyzing the outlying subjects in the study, it is clear that there are more "outlier subjects" in the typical development group. This trend may suggest that individuals in the typical development group have more heterogeneity in biomarker expressions, possibly due to a lack of ASD-specific physiological traits that standardize responses. Factors such as age, lifestyle, and individual genetic differences could lead to broader variations in biomarkers within this group, creating more natural outliers. This variability contrasts with the ASD group, where a narrower biomarker range may be influenced by common characteristics or biological patterns associated with the disorder.

### Methodological variations

Task 3

### Improved classifier

Task 4

![](images/%7BEA2B8C34-FA72-4C73-94F7-576B52323F91%7D.png)

Original Data

------------------------------------------------------------------------

![](images/Screenshot%202024-10-30%20132806.png)

Only partitioning training/testing data in the beginning

Every metric was \<=, probably because the dataset has very few observations and splitting the data makes our data even smaller

------------------------------------------------------------------------

![](images/%7B288B04D4-E7AE-4BEE-98E0-6ADAF5EF8BFB%7D.png)

Only using Variable selection using a fuzzy intersection (

Every metric decreased by a substantial amount. There could be variables that have high t-test scores but low rf importance and still be selected. This implies the hard intersection being much better than the fuzzy intersection (i.e. normalizing and then summing importance / scores and picking the top 10 proteins).

------------------------------------------------------------------------

![](images/%7B92247D20-EE0F-44B1-8F73-0CB2ADD2446F%7D.png)

Increasing the number of proteins increases every metric by a substantial amount (this was only increased to 15 proteins per test), but can be a result of overfitting.

------------------------------------------------------------------------

![](images/%7BE13BA343-E920-4393-8385-0397ADDB4875%7D.png)

Every modification used, seems like every metric is slightly worse, but could be better at predicting new data.
