---
title: "Biomarkers of ASD"
subtitle: "If you want a subtitle put it here"
author: "List names here"
date: last-modified
published-title: "Updated"
editor: visual
format: html
code-copy: true
execute:
  message: false
  warning: false
  echo: false
  cache: true
---

Use this as a template. Keep the headers and remove all other text. In all, your report can be quite short. When it is complete, render and then push changes to your team repository.

```{r}
# load any other packages and read data here
library(tidyverse)
```

## Abstract

Write a brief one-paragraph abstract that describes the contents of your write-up.

## Dataset

Write a brief data description, including: how data were obtained; sample characteristics; variables measured; and data preprocessing. This can be largely based on the source paper and should not exceed 1-2 paragraphs.

## Summary of published analysis

Summarize the methodology of the paper in 1-3 paragraphs. You need not explain the methods in depth as we did in class; just indicate what methods were used and how they were combined. If possible, include a diagram that depicts the methodological design. (Quarto has support for [GraphViz and Mermaid flowcharts](https://quarto.org/docs/authoring/diagrams.html).) Provide key results: the proteins selected for the classifier and the estimated accuracy.

## Findings

Summarize your findings here. I've included some subheaders in a way that seems natural to me; you can structure this section however you like.

### Impact of preprocessing and outliers

Tasks 1-2

### Methodlogical variations

Task 3

### Improved classifier

Task 4

![](images/{EA2B8C34-FA72-4C73-94F7-576B52323F91}.png)

Original Data

\-\--

![](images/Screenshot 2024-10-30 132806.png)

Only partitioning training/testing data in the beginning

Every metric was \<=, probably because the dataset has very few observations and splitting the data makes our data even smaller

\-\--

![](images/{288B04D4-E7AE-4BEE-98E0-6ADAF5EF8BFB}.png)

Only using Variable selection using a fuzzy intersection (

Every metric decreased by a substantial amount. There could be variables that have high t-test scores but low rf importance and still be selected. This implies the hard intersection being much better than the fuzzy intersection (i.e. normalizing and then summing importance / scores and picking the top 10 proteins).

\-\--

![](images/{92247D20-EE0F-44B1-8F73-0CB2ADD2446F}.png)

Increasing the number of proteins increases every metric by a substantial amount (this was only increased to 15 proteins per test), but can be a result of overfitting.

\-\--

![](images/{E13BA343-E920-4393-8385-0397ADDB4875}.png)

Every modification used, seems like every metric is slightly worse, but could be better at predicting new data.
